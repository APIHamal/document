#####wiredTiger存储引擎读写模型以及读写关注
        wiredTiger存储引擎读写流程
       ----------------------------
      |          内部缓冲区        |(mongodb直接操作数据区域)
       ----------------------------
        		  | 存 |
  写数据(压缩操作)| 储 |读取数据(解压操作)
        		  | 引 |  
        		  | 擎 |
       ----------------------------
      |          页缓冲区          |
       ---------------------------- 
        		  | 操 |
  写数据(压缩数据)| 作 |读取数据(压缩数据)
        		  | 系 |  
        		  | 统 |
       ----------------------------
      |      外部存储(硬盘)        |
       ---------------------------- 
#####wiredTiger存储引擎读数据流程
1)操作系统页缓存的使用
  wiredTiger存储引擎使用页(数据页的概念类似innodb存储引擎中的数据页)来管理
  集合文档数据当需要读取文档的数据时首先从内部缓冲区(类似innodb中的BufferPool)
  中判断指定的页是否存在如果不存在则继续去页缓冲区(操作系统提供的页缓冲区本质
  上就是文件在内存中的一个副本数据目的是为了加快文件的读写性能对与页缓冲区的刷
  盘操作又操作系统解决不需要用户干预)查找数据
  如果在页缓冲区也未查找到数据则从外部存储(通常是硬盘)进行加载
  加载流程如下:
  硬盘(压缩数据)--(由操作系统加载)-->页缓冲区(压缩数据)--(由wiredTiger存储引擎加载)-->内部缓冲区(已解压数据)
  #压缩数据:   wiredTiger将内部缓存区的数据写入到硬盘时会进行压缩操作
  #已解压数据: wiredTiger存储引擎将数据从页缓冲区加载到内部缓冲区时会进行解压缩操作(解压缩后数据可直接使用)
  以上如果数据页直接在内部缓冲区或者页缓冲区中命中则(如果在页缓冲区中命中则只需要一部解压缩的操作)可以
  提供近似内存的操作速度(mongodb高性能读写的原理就是利用了两层的缓冲区默认情况下这两个缓冲区可以使用掉系统中
  90%+以上的内存因此不建议将mongodb和其他服务搭建在同一台机器)
2)内部缓冲区的使用
  内部缓冲区存放集合文档数据(由存储引擎从页缓冲区加载并解压数据)mongodb的读写操作直接发生在内部缓冲区
  缓冲区的数据以B+树构建(可类比成innodb中聚簇索引的结构)内部节点存放索引信息叶子节点存放文档数据
  
#####wiredTiger存储引擎写入数据流程
1)内部缓冲区的使用
  wiredTiger存储引擎修改数据均发生在内部缓冲区中(增删改均修改内存中)并不会立即刷盘到硬盘中而是由checkPoint
  机制进行异步的刷盘(checkPoint异步刷盘时间间隔为60s)因此可能会发生[数据丢失的风险]为了避免数据丢失提供了
  预先写日志的机制(journal机制)
  #journal机制:
  wiredTiger存储引擎修改数据的同时(修改内存中数据)会写入一条journal日志(journal日志会写入journal缓冲区并不是
  直接写入硬盘中相当于关系数据库中的redo日志当崩溃发生时会进行重做操作)journal日志默认情况下会间隔100ms进行
  一次刷盘操作(所以单机mongodb实例情况下默认发生故障时会丢失100ms的数据)
  ###################################### 整体变化 ######################################
             |---(1)--->内部缓冲区的数据被修改(缓冲区默认间隔60s刷盘)
			 |
  写操作---->|(步骤[1][2]同时发生)
             |
             |---(2)--->journal缓冲区写入一条对应步骤(1)操作的journal日志(journal缓冲区默认间隔100ms刷盘)
  
#####mongodb的读写关注
1)写关注(writeConcern)
 w[0]:       无须等待任何节点写入成功不保证可靠性(类似kafka中的acks=0)发送即忘的模式[通常性能最高]
 w[1]:       等待主节点写入成功返回响应(类似kafka中的acks=1主分区写入完成后即返回[存在数据丢失的可能])
 w[n]:       等待n个节点写入成功后再返回响应
 w[majority]:等待大部分节点写入成功后再返回响应(N/2+1)该选项同时保证大部分节点写入了其自身的[journal日志]
 注意:通常情况下为了保证数据的可靠行writeConcern都应该设置成[majority(设置后自动开启journal为true表示大部分节点写入journal日志)]
2)读关注(readConcern)
 r[local]:   读取本地的数据不保证该读取的数据被大部分节点写入([因此可能发生数据回滚发生脏读])
 r[majority]:读取被大部分节点写入的数据(不会发生数据回滚的操作)
 注意:开发中为了避免读取回滚的数据产生脏读readConcern都应该设置成[majority](避免产生读取到被回滚的数据即脏数据)